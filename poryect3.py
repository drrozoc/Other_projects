# -*- coding: utf-8 -*-
"""Poryect3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oEzWYwkfEz-o6FbTdnvOwgqkG9azCicc

# Proyecto III: Test your knowledge

En este proyecto final para la asignatura Inteligencia Artificial, el objetivo es que pruebes todos tus conocimientos en el desarrollo de sistemas de clasificación utilizando redes neuronales artificiales clásicas. Para este proyecto, solucionarás el problema de clasificación del conjunto de datos **Wine Quality** del UCI Repository.

A continuación, se presentan las secciones que desarrollaremos en el notebook:

## 1. Explicación básica del problema

El conjunto de datos **Wine Quality** se centra en la clasificación de la calidad del vino basándose en varias pruebas fisicoquímicas. Este conjunto de datos incluye dos variantes de vino portugués "Vinho Verde": vino tinto y vino blanco. Los datos fueron recopilados en el norte de Portugal y fueron donados en 2009 por Paulo Cortez y sus colaboradores.

### Características del Conjunto de Datos:
- **Tamaño del Conjunto de Datos**: 4898 instancias (observaciones).
  - **Vino Tinto**: 1599 instancias.
  - **Vino Blanco**: 4898 instancias.
- **Número de Características**: 11 características de entrada y 1 característica de salida (calidad del vino).
- **Año de Donación**: 2009.
- **Fuente**: UCI Machine Learning Repository.
- **Enlace al Conjunto de Datos**: [Wine Quality](https://archive.ics.uci.edu/ml/datasets/Wine+Quality).

### Características de Entrada:
Las características de entrada son resultados de pruebas fisicoquímicas realizadas en las muestras de vino. Estas características incluyen:
1. **fixed acidity**: Acidez fija.
2. **volatile acidity**: Acidez volátil.
3. **citric acid**: Ácido cítrico.
4. **residual sugar**: Azúcar residual.
5. **chlorides**: Cloruros.
6. **free sulfur dioxide**: Dióxido de azufre libre.
7. **total sulfur dioxide**: Dióxido de azufre total.
8. **density**: Densidad.
9. **pH**: pH.
10. **sulphates**: Sulfatos.
11. **alcohol**: Alcohol.

### Característica de Salida:
La calidad del vino, que es la característica de salida, se basa en datos sensoriales y se clasifica en una escala de 0 a 10, donde:
- 0 representa una calidad muy baja.
- 10 representa una calidad muy alta.

### Objetivo del Problema:
El objetivo es desarrollar un modelo de clasificación que pueda predecir la calidad del vino basándose en sus características fisicoquímicas. Este modelo puede ser útil para bodegas y enólogos para evaluar y mejorar la calidad del vino de manera eficiente.

La clasificación de la calidad del vino es esencial para la industria vitivinícola, ya que permite a los productores identificar rápidamente las características que contribuyen a un vino de alta calidad. Además, este tipo de análisis puede ayudar en la detección de fraudes y en la optimización de los procesos de producción.

###Estrategia

Para la realicación de este proyecto es necesario realizar un analisis y tener una comprensión profunda de las variables y los datos a manejar. Puesto a que para el dataset electo de vinos y su calidad se necesita tener cierto conocimiento en el área que abarca diversos temas a distintias profundidades para en verdad comprender la relacion entre variables que hacen que un vino pueda ser calificado de forma sobresaliente, se debe restringir dentro de lo posible el analisis a identificar patrones y comportamientos de los datos y su distribución para entender como estos puden llegar a afectar la calificación final de calidad.

Por lo anterior, es indefectible el analisis de los datos para cada categoria que determine alguna caracteristica del vino, utilizamos tecnicas estadisticas para entender como se ven esas categorias respecto a los mismos datos, y encontrar la similitud y los patrones logicos que conlleven a una eleccion de un vino en algun rango de calidad, asi como comprender los rangos en los cuales se miden. Suponemos que este dataset no se refiere a la calidad de los vinos de una forma cualitativa sino cuantitativa debido a que al final el gusto por un vino solo dependera del usuario que lo pruebe, no obstante se entiende de que existen ciertos margenes de calidad de produccion(ph, acidez, azucar, composicion, entre otros) que permiten estimar cuales vinos tuvieron un proceso de fabricacion mas cauteloso y por lo tanto pueden llegar a tener un mejor recibimiento que otros.

 Con base en estos valores y sus vairables se implementaran diferentes modelos de clasificación, puesto a que al final a priori de la revision de los datos un vino solo puede ser categorizado entre 0 y 10, por lo tanto se deben implementar diferentes modelos de clasificacion con el fin de encontrar el que mejor tenga predicción a los datos de manera más eficiente y simple.

## 2. Tratamiento de los datos
### 2.1 Cargar los Datos y Librerías
"""

# Importar las librerías necesarias
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_wine
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler

# Configuración de estilo para los gráficos
plt.style.use('ggplot')  # Cambiar a un estilo disponible por defecto

# Cargar el conjunto de datos
datos_vino_tinto = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')
datos_vino_blanco = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')

# Mostrar las primeras filas de cada conjunto de datos y verificar que el archivo
#y su integridad se mantienen.
print("Datos de Vino Tinto:")
display(datos_vino_tinto.head())

print("\nDatos de Vino Blanco:")
display(datos_vino_blanco.head())

"""## 3. Análisis exploratorio de datos

Realizaremos un análisis exploratorio de los datos para visualizar la distribución de las características y su correlación.

### Descripción Estadística Inicial

En esta subsección, proporcionamos una descripción estadística de las características del conjunto de datos de vino tinto y vino blanco. Las estadísticas descriptivas incluyen medidas como la media, mediana, desviación estándar, valores mínimos y máximos, así como los percentiles. Esto nos ayuda a comprender la distribución y el rango de los valores en cada característica. Además, contamos los valores nulos en cada conjunto de datos para asegurarnos de que no haya datos faltantes que puedan afectar nuestro análisis.

#### Resultados:
- **Media (Mean)**: Es el promedio de los valores de cada característica.
- **Mediana (Median)**: Es el valor central que separa la mitad superior de la mitad inferior de los datos.
- **Desviación Estándar (Std)**: Mide la dispersión de los datos respecto a la media. Un valor alto indica una mayor variabilidad.
- **Valores Mínimos y Máximos (Min, Max)**: Indican los valores más pequeños y más grandes de cada característica.
- **Percentiles (25%, 50%, 75%)**: Indican los puntos de corte que dividen los datos en cuatro partes iguales.

#### Código:
"""

# Descripción estadística de los datos de vino tinto y vino blanco
print("Descripción Estadística - Vino Tinto")
display(datos_vino_tinto.describe())

print("\nDescripción Estadística - Vino Blanco")
display(datos_vino_blanco.describe())

"""#Análisis:
Los datos anteriormente presentados nos ayudan a comprender cual seria en verdad el marco de calificacion y el promedio real, el verdadero vino "promedio" con base es sus caracteristicas medias. Así mismo podemos comparar para los vinos balnco y tintos sus caracteristicas generales y diferenias , por ejemplo según las tablas los vinos de mayor acidez fija son los vinos tintos, que los vinos blancos tienden a tener un mayor aporte de azucar residual, y que ambos tienen relativamente un mismo nivel de densidad y acidez.  

Algunas aspectos importantes a considerar son:

- La minima calidad del vino tinto y blanco es 3, y el máximo es 8 y 9 respectivamente. Es importante está medida para que se pueda considerar posteriormente como se va a realizar el sistema de categorzación de los resultados.
-La distribución de los datos se vuelve un factor muy importante debido a que si si por ejemplo se entrena el modelo con datos aleatorios del 70% del dataset y estos solo contemplan por casualidad para las variables el cuartil en el cual no se encuentra la información como es el caso del azucar residual, para mejorar la visualización de los mismo se va a ver por medio de histogramas la distribucion de los datos, permitiendo identificar datos atipicos y distribución de la información.

### Distribución de Variables

En esta subsección, visualizamos la distribución de cada característica en el conjunto de datos de vino tinto y vino blanco utilizando histogramas. Los histogramas muestran cómo se distribuyen los valores de cada característica, lo que nos permite identificar patrones, sesgos y la presencia de valores atípicos (outliers). Esta visualización es fundamental para entender la variabilidad y la forma de las distribuciones de los datos.

#### Resultados:
- Los **histogramas** permiten observar cómo se distribuyen los datos de cada característica.
- Nos ayudan a identificar si los datos están **sesgados** (concentrados hacia un lado).
- Los histogramas también revelan la presencia de **valores atípicos (outliers)**.

#### Código:
"""

# Histograma para cada característica
datos_vino_tinto.hist(bins=15, figsize=(15, 10))
plt.suptitle("Distribución de las Características - Vino Tinto")
plt.show()

datos_vino_blanco.hist(bins=15, figsize=(15, 10))
plt.suptitle("Distribución de las Características - Vino Blanco")
plt.show()

"""#Análisis:
Como se puede evidenciar en los histogramas se pueden sacar conclusiones respecto a la distribución de los datos para cada tipo y se puede determinar cuales variables son enteras o decimales. La mayoría de lso datos tiende a presentar un tipo de silueta asemejada a la normal, con sesgos de izquierda o derecha en algunos casos. La idea del modelo de clasificacion es que tome para un espacio R^(12) en el entrenamiento la asociacion de los distintos niveles de las caracteristicas y se asocien y relacionen con una calificacion.

De los niveles de calificacion podemos observar que no existen calificaciones para los niveles 0,1,2, y 10. Asi mismo que los niveles 3 y 9 no tienen un valor significativo al momento de recibir una clasificacion, y como se vio previamente la verdadera "media" de los datos se encuentra no en el nivel de calidad 5 como entenderia una persona facilmente en una clasificacion del 0 al 10 si no del 3 al 9 con una media en 6. Tomando en cuenta estos niveles de clasificacion consideramos pertinente omitir los puntos de clasificacion que no obtuvieron resultados, justificandolo en que si el modelo no conoce un patron de datos que lleve a un resultado superior a 9 o inferior a 3 ningun clasificador deberia ser puesto en estos puntos. Quedán entonces 7 posibles clasificadores. Notamos también que las puntuaciones extremas son muy escazas, por lo cual consideramos mas provechoso definir en vez de una escala de 7 categorias 3 tipos de clasificacion para los vinos para asociados con su nivel de ocurrencia y clasificación.

En ese orden de ideas si el vino tiene una calificación menor o igual a 5 será catalogado como un vino de calidad básica, si se encuentra en 6 será clasificado como un vino de calidad moderada, y para valores mayores a 6 de calidad avanzada.

### Matriz de Correlación

En esta subsección, utilizamos matrices de correlación para visualizar las relaciones entre las características del conjunto de datos de vino tinto y vino blanco. La matriz de correlación muestra el coeficiente de correlación de Pearson entre cada par de características, que varía entre -1 y 1. Un valor cercano a 1 indica una fuerte correlación positiva, un valor cercano a -1 indica una fuerte correlación negativa, y un valor cercano a 0 indica poca o ninguna correlación. Estas matrices nos ayudan a identificar características que están altamente correlacionadas, lo que puede ser útil para la selección de características y para entender las relaciones internas en los datos.

#### Resultados:
- La **matriz de correlación** muestra cómo se relacionan las características entre sí.
- **Colores oscuros** indican correlaciones fuertes (positivas o negativas).
- **Colores claros** indican poca o ninguna correlación.

#### Código:
"""

# Matriz de correlación para vino tinto
plt.figure(figsize=(12, 8))
sns.heatmap(datos_vino_tinto.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title("Matriz de Correlación - Vino Tinto")
plt.show()

# Matriz de correlación para vino blanco
plt.figure(figsize=(12, 8))
sns.heatmap(datos_vino_blanco.corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)
plt.title("Matriz de Correlación - Vino Blanco")
plt.show()
#

"""#Análisis:
La matriz de correlación es un gran aliado al momento de indentificar las relaciones entre varibles de manera directa o inversa aún sin comprender la totalidad de condiciones y variables necesarias e intrinsecas al proceso en si. Un ejemplo intuitivo puede ser la acidez de un vino, que puede hacer que un usuario guste en mayor medida o no del mismo, dicha varible en realidad depende de la variedad de la uva, el clima y las condiciones de cultivo, la madurez de la uva en el momento de la cosecha, las practicas de vinificacion, adicion de acidos, condiciones del suelo, entre otros factores, no osbtante el unico interes para el caso es encontrar el punto de acidez idoneo para que la clasificacion del vino aumente, como la relacion que tiene directa o inversa con las demás variables, es decir, si la acidez aumenta o disminuye como se comportan las demás variables o si les es independiente, si lo es hasta que punto lo son.

Como es de esperarse la correlacion es completa en la diagonal porque es en donde cada variable coincide con la misma, por lo que la relación es completa y directa.

Para el vino tinto:
- La acidez fija se relaciona de manera directamente proporcional con el acido citrico y la densidad, pero inversamente proporcional con el ph, el resultado tiene sentido puesto a que cuanto mas acido es una sustancia el valor de ph disminuye.  También concluímos que a mayor densidad debería haber un ligero incremento en la acidez.

-La acidez volatil tiene una relación inversa con el acido citrico.

-El azucar residual, los cloruros se comportan como una variable independiente, podrían ser despreciados del modelo.

- El dioxido de sulfuro y el dioxido de sulfuro total como era de esperase tienen una relación directamente proporcional entre ellos mismos.

-La densidad tiene una relación ligeramente inversa con el nivel de alcohol adicional a las relaciones previamente mencioandas.

- Ls sulfatos tienen una ligera relación con los cloruros, el acido citrio, y la calificación.

-El alcohol tiene una relación considerable con la densidad de manera inversa, y con la calificación de manera directa.


Presentadas las principales relaciones entre variables retomamos nuestro objetivo, el cuál será la clasificación, por lo tanto determinamos las variables que mayor relación tienen con la calificación serán la volatividad del acido a nivel inverso, y directamente proporcional el nivel de alcohol y el acido citrico, aunque con un impacto muy moderado.

Para el vino blanco encontramos relaciones muy similares a las del vino tinto, su relación de variables será la siguiente:

- El acido fijo tiene una relación inversa con el PH, y una ligera relación directa con el acido citrico y la densidad.

- La volatilidad de acido, los cloruros, y los sulfatos  no tienen relaciones significativas con ninguna variable.

- El residuo de azucar presenta a diferencia del vino tinto una estrecha relación con la densidad, y una relacion moderada con el alcohol, aunque la densidad tiene una relación inversa con el alcohol.

- El dioxido de sulfuro libre y total tiene una relación estecha consigo mismos.


Conlcuimos que las variables para el vino tinto que mayormente influyen en la clasificacion son la densidad y el alcohol.


A manera global el alcohol es el principal determinante de la calificacion de calidad con una relacion directamente proporcional, y la densidad al ser un afectante del alcohol tambien gana mucha relevancia como ciertos acidos, es decir a manera general, los vinos presentados tenian una mejor clasificacion si su nivel de alcohol era mayor y su densidad era menor, como su acidez. No obstante estas relaciones se encuentran "ponderadas" puesto a que sigue sin ser directa 1 o -1 en la matriz de correlacion.

### Análisis de la Variable Objetivo

En esta subsección, analizamos la distribución de la calidad del vino, que es la variable objetivo en nuestro análisis. Utilizamos gráficos de barras para mostrar la frecuencia de cada nivel de calidad en los conjuntos de datos de vino tinto y vino blanco. Este análisis nos ayuda a entender cómo se distribuyen las diferentes calidades de vino y a identificar cualquier desbalance en las clases, lo que puede influir en el rendimiento de nuestros modelos de clasificación.

#### Resultados:
- Los **gráficos de barras** muestran cuántos vinos pertenecen a cada nivel de calidad.
- Un **desbalance** en las clases puede indicar que hay muchas más muestras en ciertas calidades que en otras.

#### Código:
"""

# Distribución de la calidad del vino
plt.figure(figsize=(12, 6))
sns.countplot(x='quality', data=datos_vino_tinto, palette='viridis')
plt.title("Distribución de la Calidad - Vino Tinto")
plt.show()

plt.figure(figsize=(12, 6))
sns.countplot(x='quality', data=datos_vino_blanco, palette='viridis')
plt.title("Distribución de la Calidad - Vino Blanco")
plt.show()

"""Como se explico a detalle previamente la mayor cantidad de vinos clasificados se encuentra en una escala media entre 5 y 6 siendo los vinos blancos de mejor calidad en general. Lo clave es tomar en cuenta que las relaciones para vino tinto y vino blanco varian, por lo que un primer criterio para identificar los parametros sera si el vino es de la categoria tinto o blanco. De igual forma ya que las relaciones no son estrictamente directas el modelo podria predecir en su globalidad la calidad tomando en cuenta ambas categorias.

### Comparación entre Vino Tinto y Vino Blanco

En esta subsección, comparamos las características entre los conjuntos de datos de vino tinto y vino blanco utilizando boxplots. Los boxplots nos permiten visualizar la distribución de cada característica y comparar las diferencias entre las dos clases de vino. Esta comparación nos ayuda a identificar qué características varían significativamente entre los vinos tinto y blanco, lo cual puede ser útil para la clasificación y el análisis de calidad.

#### Resultados:
- Los **boxplots** muestran la distribución de los datos y la presencia de valores atípicos.
- Podemos observar **diferencias significativas** entre las características de vino tinto y blanco.

#### Código:
"""

# Boxplots para comparar características entre vino tinto y blanco
plt.figure(figsize=(12, 8))

# Concatenar los datos de vino tinto y vino blanco
datos_vinos = pd.concat([datos_vino_tinto.assign(tipo='Tinto'), datos_vino_blanco.assign(tipo='Blanco')], ignore_index=True)

# Convertir a formato largo para seaborn
datos_largos = pd.melt(datos_vinos, id_vars=['tipo'], var_name='Característica', value_name='Valor')

# Crear el boxplot
sns.boxplot(data=datos_largos, x='Característica', y='Valor', hue='tipo')
plt.xticks(rotation=90)
plt.title("Comparación de Características - Vino Tinto y Blanco")
plt.show()

"""El diagrama anterior es otro apoyo para ayudanrnos a validar la confiabilidad de las tablas  y los datos subidos,  e identificar posibles valores atipicos. En la comparacion podemos ver que por ejemplo no es lo mismo evaluar el dioxido de sulfuro libre y total para ambos vinos, y que este parametro puede ser un gran diferenciador entre ambos  en relacion con sus variables locales.

### 4. Esquema de Entrenamiento

En esta sección, entrenaremos y evaluaremos cuatro modelos de clasificación en los datos de calidad del vino. Usaremos Regresión Logística, Random Forest, LDA y Redes Neuronales.

#### Preparación de los Datos

Primero, dividimos los datos en conjuntos de entrenamiento y prueba, y normalizamos las características para que los modelos funcionen de manera más efectiva.
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Separar las características (X) y la variable objetivo (y)
X_tinto = datos_vino_tinto.drop('quality', axis=1)
y_tinto = datos_vino_tinto['quality']

X_blanco = datos_vino_blanco.drop('quality', axis=1)
y_blanco = datos_vino_blanco['quality']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train_tinto, X_test_tinto, y_train_tinto, y_test_tinto = train_test_split(X_tinto, y_tinto, test_size=0.2, random_state=42)
X_train_blanco, X_test_blanco, y_train_blanco, y_test_blanco = train_test_split(X_blanco, y_blanco, test_size=0.2, random_state=42)

# Normalizar los datos
scaler = StandardScaler()

X_train_tinto = scaler.fit_transform(X_train_tinto)
X_test_tinto = scaler.transform(X_test_tinto)

X_train_blanco = scaler.fit_transform(X_train_blanco)
X_test_blanco = scaler.transform(X_test_blanco)

"""##Comprension de métodos de validación

#Matriz de confusión:
La matriz de confusión es una herramienta fundamental en la evaluación de modelos de clasificación. Representa la relación entre las predicciones del modelo y las clases reales de los datos. Esta matriz organiza los resultados de la clasificación en cuatro categorías: verdaderos positivos (TP), verdaderos negativos (TN), falsos positivos (FP) y falsos negativos (FN). Los verdaderos positivos son las instancias correctamente clasificadas como positivas, mientras que los verdaderos negativos son las instancias correctamente clasificadas como negativas. Los falsos positivos son instancias que el modelo predijo incorrectamente como positivas cuando en realidad son negativas, y los falsos negativos son instancias que el modelo predijo incorrectamente como negativas cuando en realidad son positivas. La matriz de confusión proporciona una visión clara de cómo el modelo está funcionando en términos de precisión y cobertura en cada clase.

#Recall
El recall, también conocido como sensibilidad o tasa de verdaderos positivos, es una métrica importante en la evaluación de modelos de clasificación, especialmente en casos donde la identificación de casos positivos es crítica. Mide la capacidad del modelo para identificar correctamente todas las instancias positivas en el conjunto de datos. Matemáticamente, se calcula como la proporción de instancias positivas reales que el modelo predijo correctamente, dividiendo el número de verdaderos positivos (TP) entre la suma de verdaderos positivos y falsos negativos (FN). En términos más simples, el recall responde a la pregunta "De todas las instancias positivas reales, ¿cuántas fueron identificadas correctamente por el modelo?". Un alto recall indica que el modelo es capaz de identificar la mayoría de las instancias positivas, lo que sugiere una buena capacidad para detectar la clase objetivo.

#F1-score

El F1-score es una métrica que combina precision y recall en una sola medida para proporcionar una evaluación equilibrada del rendimiento de un modelo de clasificación. Es especialmente útil cuando hay un desequilibrio entre las clases en el conjunto de datos. El F1-score se calcula como la media armónica de precision y recall, lo que le otorga más peso a las métricas más bajas. Matemáticamente, se calcula como 2 veces el producto de precision y recall, dividido por la suma de precision y recall. Un F1-score más alto indica un mejor equilibrio entre precision y recall, lo que sugiere un mejor rendimiento general del modelo en la tarea de clasificación. Esta métrica es particularmente útil cuando se busca un balance entre la capacidad del modelo para clasificar correctamente las instancias positivas y minimizar los falsos positivos y falsos negativos.

#### Modelos de Clasificación

### Regresión Logística

La Regresión Logística es un modelo lineal utilizado para la clasificación binaria. En nuestro caso, la adaptamos para la clasificación multiclase.


 La regresión logística es una técnica de modelado estadístico utilizada para predecir la probabilidad de una clase o evento binario. A diferencia de la regresión lineal que predice valores continuos, la regresión logística predice la probabilidad de que una observación pertenezca a una de dos clases (por ejemplo, éxito o fracaso, sí o no, 0 o 1). El modelo se basa en la función logística o sigmoide, que transforma la salida de una combinación lineal de las características en una probabilidad que
varía entre 0 y 1. Esto se hace mediante la ecuación logística: P(y=1|X) = 1 / (1 + exp(-(β0 + β1*X1 + ... + βn*Xn))), donde P(y=1|X) es la probabilidad de que el resultado sea 1 dado el conjunto de características X.  La evaluación del modelo se realiza mediante métricas como la precisión, matriz de confusión, y reportes de clasificación que detallan la precisión, recall y F1-score.
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Entrenar el modelo de Regresión Logística
log_reg = LogisticRegression(max_iter=1000)
log_reg.fit(X_train_tinto, y_train_tinto)

# Realizar predicciones
y_pred_log_reg = log_reg.predict(X_test_tinto)

# Evaluar el modelo
print("Regresión Logística - Vino Tinto")
print("Accuracy:", accuracy_score(y_test_tinto, y_pred_log_reg))
print(confusion_matrix(y_test_tinto, y_pred_log_reg))
print(classification_report(y_test_tinto, y_pred_log_reg, zero_division=0))

"""Accuracy: La precisión del modelo, que es la proporción de predicciones correctas sobre el total de predicciones.

Confusion Matrix (Matriz de Confusión): Muestra el rendimiento del modelo en términos de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.

Classification Report: Incluye métricas detalladas como precisión, recall y F1-score para cada clase.

Al examinar la matriz de confusión, se revela que hay una cantidad significativa de errores de clasificación en varias clases. Por ejemplo, en la clase 5, de 130 muestras, solo 98 se clasificaron correctamente, mientras que 32 se clasificaron incorrectamente. Similarmente, en la clase 6, de 132 muestras, 76 se clasificaron correctamente, mientras que 46 se clasificaron incorrectamente. Esto sugiere que el modelo tiene dificultades para distinguir entre las clases 5 y 6.

Para la clase 5, el recall es del 75%, lo que significa que el modelo identificó correctamente el 75% de todas las instancias reales de la clase 5. Sin embargo, para la clase 7, el recall es solo del 21%, lo que indica que el modelo tuvo dificultades para identificar correctamente las instancias reales de la clase 7.

F1-score promedio es del 55%, lo que sugiere un rendimiento moderado del modelo en términos de balance entre precision y recall.

##Random Forest

El Random Forest es un modelo basado en árboles de decisión que utiliza múltiples árboles para mejorar la precisión y evitar el sobreajuste.


Un Random Forest es un modelo de aprendizaje automático que utiliza un conjunto de árboles de decisión para realizar tareas de clasificación o regresión. Conceptualmente, un Random Forest crea múltiples árboles de decisión durante el entrenamiento y los utiliza para mejorar la precisión y controlar el sobreajuste. Cada árbol de decisión en el bosque se construye a partir de una muestra aleatoria del conjunto de entrenamiento, y en cada nodo del árbol se selecciona un subconjunto aleatorio de características para determinar la mejor división. Este proceso de muestreo aleatorio de datos y características introduce variedad entre los árboles, lo que generalmente resulta en un modelo más robusto y preciso. La predicción final de un Random Forest para una observación nueva se obtiene mediante la agregación de las predicciones de todos los árboles individuales, generalmente utilizando la votación mayoritaria para problemas de clasificación. Este enfoque ayuda a reducir
 la variabilidad (reduciendo el sobreajuste) y a aumentar la precisión general del modelo.
"""

from sklearn.ensemble import RandomForestClassifier

# Entrenar el modelo de Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_tinto, y_train_tinto)

# Realizar predicciones
y_pred_rf = rf.predict(X_test_tinto)

# Evaluar el modelo
print("Random Forest - Vino Tinto")
print("Accuracy:", accuracy_score(y_test_tinto, y_pred_rf))
print(confusion_matrix(y_test_tinto, y_pred_rf))
print(classification_report(y_test_tinto, y_pred_rf, zero_division=0))

"""Al examinar la matriz de confusión, se nota que aunque se ha mejorado en comparación con la regresión logística, todavía existen errores de clasificación en varias clases. Por ejemplo, en la clase 5, de 130 muestras, 96 se clasificaron correctamente, pero 33 se clasificaron incorrectamente. Similarmente, en la clase 6, de 132 muestras, 92 se clasificaron correctamente, pero 31 se clasificaron incorrectamente. Esto sugiere que aunque Random Forest ha mejorado en comparación con la regresión logística, aún tiene dificultades para distinguir entre algunas clases.

Al observar el informe de clasificación, se puede apreciar que aunque el recall ha mejorado en comparación con la regresión logística, todavía hay variabilidad significativa entre las clases. Para la clase 5, el recall es del 74%, lo que significa que el modelo identificó correctamente el 74% de todas las instancias reales de la clase 5. Sin embargo, para la clase 7, el recall es del 55%, lo que indica que el modelo tuvo dificultades para identificar correctamente las instancias reales de la clase 7.

En cuanto al F1-score, aunque se ha mejorado ligeramente en comparación con la regresión logística, sigue siendo moderado. El F1-score promedio es del 64%, lo que sugiere un rendimiento decente del modelo en términos de balance entre precision y recall.

Resultados:

Accuracy: Proporción de predicciones correctas.

Confusion Matrix: Desempeño del modelo en términos de clasificación correcta e incorrecta.

Classification Report: Métricas detalladas para cada clase.
"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

# Entrenar el modelo de LDA
lda = LinearDiscriminantAnalysis()
lda.fit(X_train_tinto, y_train_tinto)

# Realizar predicciones
y_pred_lda = lda.predict(X_test_tinto)

# Evaluar el modelo
print("LDA - Vino Tinto")
print("Accuracy:", accuracy_score(y_test_tinto, y_pred_lda))
print(confusion_matrix(y_test_tinto, y_pred_lda))
print(classification_report(y_test_tinto, y_pred_lda, zero_division=0))

"""El modelo clasifica correctamente alrededor del 55.9% de las instancias de prueba. Al examinar la matriz de confusión, se nota que hay una cantidad considerable de errores de clasificación en varias clases. La clase 5, de 130 muestras, 96 se clasificaron correctamente, pero 31 se clasificaron incorrectamente. En la clase 6, de 132 muestras, 70 se clasificaron correctamente, pero 45 se clasificaron incorrectamente.

Se observa una variabilidad significativa en el recall entre las clases, lo que indica que el modelo tiene dificultades para identificar correctamente algunas clases. La clase 5, el recall es del 74%, mientras que para la clase 7 es del 31%. El F1-score promedio es del 54%, lo que sugiere un rendimiento moderado del modelo en términos de balance entre precision y recall.

Resultados:

Accuracy: Precisión del modelo.
Confusion Matrix: Rendimiento del modelo en la clasificación.
Classification Report: Métricas detalladas para cada clase.

Redes neuronales
Las Redes Neuronales son modelos inspirados en la estructura del cerebro humano, capaces de aprender patrones complejos en los datos.


Las redes neuronales(NN) están inspiradas en la estructura y el funcionamiento del cerebro humano. Un modelo específico de NN es el Perceptrón Multicapa (MLP), que consiste en una capa de entrada, una o más capas ocultas y una capa de salida. Cada capa está compuesta por nodos (neuronas), que están interconectados a través de pesos. Los datos de entrada se pasan a través de la red, donde cada nodo realiza una operación lineal seguida de una función de activación no lineal, como ReLU o Sigmoid. Durante el entrenamiento, el modelo ajusta los pesos utilizando un algoritmo de optimización, como el descenso de gradiente, para minimizar la diferencia entre las predicciones y los valores reales. Este proceso permite a las redes neuronales capturar relaciones no lineales complejas en los datos. Después de entrenar el modelo, se pueden hacer predicciones sobre nuevos datos pasando estos a través de la red y obteniendo una salida que indica la probabilidad de pertenencia a cada clase. En el código, se entrena un MLP en datos escalados y se evalúa su rendimiento utilizando la precisión, la matriz de confusión y el informe de clasificación.
"""

from sklearn.neural_network import MLPClassifier

# Entrenar el modelo de Redes Neuronales
mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
mlp.fit(X_train_tinto, y_train_tinto)

# Realizar predicciones
y_pred_mlp = mlp.predict(X_test_tinto)

# Evaluar el modelo
print("Redes Neuronales - Vino Tinto")
print("Accuracy:", accuracy_score(y_test_tinto, y_pred_mlp))
print(confusion_matrix(y_test_tinto, y_pred_mlp))
print(classification_report(y_test_tinto, y_pred_mlp, zero_division=0))

"""El modelo clasifica correctamente alrededor del 62.8% de las instancias de prueba.  La clase 5, de 130 muestras, 96 se clasificaron correctamente, pero 28 se clasificaron incorrectamente. Similarmente, en la clase 6, de 132 muestras, 85 se clasificaron correctamente, pero 36 se clasificaron incorrectamente.

Al observar el informe de clasificación, se aprecia que la interpretación es similar a la de los modelos anteriores. Se observa una variabilidad significativa en el recall entre las clases, lo que indica que el modelo tiene dificultades para identificar correctamente algunas clases. La clase 5, el recall es del 74%, mientras que para la clase 7 es del 40%. Además, el F1-score promedio es del 62%, lo que sugiere un rendimiento moderado del modelo en términos de balance entre precisión y recall.

Resultados:

Accuracy: Precisión del modelo.
Confusion Matrix: Desempeño del modelo.
Classification Report: Métricas detalladas para cada clase.

##Validacion cruzada

A continuación comenzaremos a validar cual es el rendimiento de los modelos utilizando la validación cruzada, este proceso se consiste en decidir si los resultados digitales que cuantifican las relaciones hipotéticas entre las variables son aceptables como descripciones de los datos.

El metodo consiste en realizar una separación de los datos, conocido como train & split, en dónde se utiliza por lo menos el 70% u 80% de los datos y un testeo con los datos restantes, 20% a 30% de los datos.
"""

# Combinar los datos de vino tinto y blanco
datos_vino_tinto['type'] = 'red'
datos_vino_blanco['type'] = 'white'
datos_vino = pd.concat([datos_vino_tinto, datos_vino_blanco], ignore_index=True)

# Separar características (X) y variable objetivo (y)
X = datos_vino.drop(columns=['quality', 'type'])
y = datos_vino['quality']

# Normalizar los datos
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Definir los modelos
models = {
    "LDA": LinearDiscriminantAnalysis(),
    "Logistic Regression": LogisticRegression(max_iter=10000),
    "Random Forest": RandomForestClassifier(n_estimators=100),
    "MLP": MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
}

# Configurar la validación cruzada
kf = KFold(n_splits=5, shuffle=True, random_state=1)

# Evaluar cada modelo utilizando validación cruzada
results = {}
for model_name, model in models.items():
    try:
        cv_scores = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')
        results[model_name] = cv_scores
    except Exception as e:
        results[model_name] = str(e)

# Mostrar resultados
results_df = pd.DataFrame(results).T
results_df.columns = [f'Fold {i+1}' for i in range(kf.get_n_splits())]
results_df['Mean Accuracy'] = results_df.mean(axis=1)
results_df['Std Deviation'] = results_df.std(axis=1)

results_df

"""### Paso a Paso del Proceso

1. **Carga de Datos**:
   Los datos se cargan desde un archivo CSV. En nuestro caso, utilizamos un dataset de vinos (`wine_data.csv`).

2. **Preprocesamiento de Datos**:
   - Codificación de características categóricas: Si el dataset contiene variables categóricas, estas se convierten a variables numéricas usando codificación (por ejemplo, one-hot encoding).
   - Normalización o estandarización: Las características numéricas se normalizan o estandarizan para asegurar que todas tengan la misma escala.

3. **Separación de Características y Variable Objetivo**:
   - `X` contiene todas las características del dataset.
   - `y` contiene la variable objetivo, que es la calidad del vino en este caso.

4. **División en Conjuntos de Entrenamiento y Prueba**:
   - Usamos `train_test_split` para dividir el dataset en un 70% para entrenamiento y un 30% para prueba, con una semilla aleatoria de 42 para reproducibilidad.

5. **Inicialización del Modelo**:
   - Utilizamos `LogisticRegression` con un número máximo de iteraciones de 1000 para asegurar que el algoritmo converja.

6. **Configuración de K-Fold Cross-Validation**:
   - Configuramos `KFold` con 5 pliegues, barajando los datos antes de cada división y estableciendo una semilla para reproducibilidad.

7. **Validación Cruzada**:
   - Usamos `cross_val_score` para calcular las puntuaciones de validación cruzada en el conjunto de entrenamiento. Este proceso se repite 5 veces (k=5), promediando las puntuaciones obtenidas para obtener una estimación más robusta del rendimiento del modelo.

8. **Entrenamiento y Evaluación del Modelo**:
   - Entrenamos el modelo en el conjunto de entrenamiento completo y lo evaluamos en el conjunto de prueba.
   - Se imprimen la matriz de confusión, el reporte de clasificación y la exactitud del conjunto de prueba.
   - También se imprimen las puntuaciones de validación cruzada y su promedio.

#Análisis

Se toma en cuenta en primera instancia que para evaluar un modelo no solo se debe verificar su eficiencia y precision a la hora de realizar la tarea, si no también la dificultad asociada a la implementación del modelo, siendo los modelos de menor complejidad pero mayor precision los optimos, no obstante, esto dependera de la aplicación, es decir, si el modelo es muy complejo y se obtiene una pequeña ventaja en precision y la aplicacion no es de vital importancia se puede hablar de que el modelo de menor precision si no es extrema pero mas simple puede ser la mejor eleccion, si por el contrario la precision es un factor determinante, como lo es por ejemplo en casos medicos hasta la mas pequeña diferencia puede causar un impacto significativo.

El modelo de Linear Discriminant Analysis (LDA) mostró una precisión media del 53.82%, con una desviación estándar de 1.11%. Esto indica que, aunque el modelo tiene un rendimiento relativamente consistente, su precisión no es muy alta para este conjunto de datos. En comparación, la Regresión Logística obtuvo una precisión media ligeramente superior del 54.36% y una desviación estándar más baja de 0.85%, sugiriendo que este modelo es un poco más fiable y consistente que el LDA en este contexto.

El modelo de Random Forest destacó con la mayor precisión media del 67.74% y una desviación estándar moderada de 1.34%. Estos resultados sugieren que Random Forest es el modelo más preciso entre los evaluados, manteniendo un rendimiento bastante consistente. Por otro lado, el Multi-Layer Perceptron (MLP) logró una precisión media del 57.16%, que es superior a las de LDA y Regresión Logística, pero inferior a la de Random Forest. Sin embargo, el MLP mostró la desviación estándar más baja de 0.55%, indicando que su rendimiento es muy consistente a través de las diferentes particiones del conjunto de datos.

En conclusión, en términos de precisión media, el modelo de Random Forest se desempeña mejor que los otros modelos, lo que sugiere su idoneidad para este conjunto de datos. Ademas, entendemos que el modelo de Random Forest no necesita una eficiencia computacional Sin embargo, si se prioriza la consistencia del rendimiento, el MLP podría ser una opción preferible debido a su baja desviación estándar. Los modelos de LDA y Regresión Logística, aunque muestran precisiones medias similares, con la Regresión Logística ofreciendo un rendimiento ligeramente mejor y más consistente que LDA.

#Modelos:

LDA se basa en suposiciones estadísticas claras sobre la normalidad multivariante y la homogeneidad de las covarianzas, lo que simplifica su implementación y hace que su uso sea relativamente directo. En comparación, Regresión Logística también es bastante accesible, extendiendo los conceptos de regresión lineal a un contexto de clasificación binaria. Sin embargo, requiere una comprensión adicional sobre la interpretación de coeficientes y la posible necesidad de regularización para evitar el sobreajuste, lo que añade una capa de complejidad respecto a LDA.

Random Forest, en contraste, introduce una mayor complejidad tanto conceptual como computacional. A diferencia de los modelos lineales, Random Forest combina múltiples árboles de decisión, lo que puede aumentar el nivel de complejidad de implementación por su entendimiento teorico.  Las redes neuronales artificiales requieren decisiones sobre la arquitectura (número de capas y neuronas), selección de funciones de activación y algoritmos de optimización, y manejo de técnicas para evitar el sobreajuste como la regularización y el dropout. Esta complejidad en diseño y entrenamiento posiciona al MLP como el modelo más desafiante, tanto en teoría como en práctica, en comparación con LDA, regresión logística y Random Forest.


Para el desarrollo de este proyecto se podria argumentar que el mejor modelo a utilizar es de random forest, la aplicacion no requiere una precision cuyas consecuencias sean de alto impacto por lo cual puede ser una buena alternativa elegir el modelo de mayor precision, puesto a que los modelos en general cuentan con una eficiencia muy baja. Como resultado, Random forest puede ser un modelo cuya relacion de complejidad precision puede ser idonea para este despliegue.

#Estrategias de mejora:

### Linear Discriminant Analysis (LDA)

Para mejorar el rendimiento del modelo de LDA en el conjunto de datos del vino, crear nuevas características relevantes o transformar las existentes, puede contribuir significativamente a mejorar el rendimiento de LDA. Por ejemplo, combinar características relacionadas con la acidez y el contenido de azúcar podría proporcionar información más rica para la clasificación de la calidad del vino.

### Regresión Logística

El rendimiento de la regresión logística en el conjunto de datos del vino puede mejorarse  realizando una selección de características para eliminar aquellas que no aportan información relevante, mejorando así la eficiencia y precisión del modelo.

### Random Forest

Para mejorar el rendimiento del modelo de Random Forest en el conjunto de datos del vino, ajustar el número de árboles es una de las estrategias más directas. Generalmente, más árboles resultan en una mejor precisión hasta un cierto punto. Ajustar el número de características consideradas para cada división (submuestreo de características) puede ayudar a crear árboles más diversos y reducir la correlación entre ellos, mejorando así la precisión general.

### Redes neuronales

Mejorar el rendimiento de una red neuronal en el conjunto de datos del vino requiere ajustar varios aspectos de su arquitectura y entrenamiento. Probar diferentes números de capas y neuronas por capa puede para encontrar la estructura óptima para el problema específico. Además, ajustar la tasa de aprendizaje y experimentar con diferentes optimizadores, como SGD, Adam o RMSprop, puede resultar en un entrenamiento más eficiente y en un mejor rendimiento del modelo. L

### Consideraciones Generales

Independientemente del modelo,  aumentar el tamaño del conjunto de datos mediante la recolección de más datos reales puede ser particularmente beneficioso, especialmente para algoritmos que se benefician de grandes volúmenes de datos. Evaluar diferentes configuraciones de preprocesamiento y algoritmos de aprendizaje puede proporcionar una visión más completa y ayudar a identificar las mejores estrategias para mejorar el rendimiento.
"""

# @title Accuracy

from matplotlib import pyplot as plt
results_df['Mean Accuracy'].plot(kind='hist', bins=20, title='Accuracy')
plt.gca().spines[['top', 'right',]].set_visible(False)

"""## 8. Selección y justificación del mejor modelo


"""

from sklearn.preprocessing import StandardScaler

# Configuración de estilo para los gráficos
plt.style.use('ggplot')

# Cargar el conjunto de datos
datos_vino_tinto = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=';')
datos_vino_blanco = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=';')

# Preprocesamiento de los datos
X_tinto = datos_vino_tinto.drop('quality', axis=1)
y_tinto = datos_vino_tinto['quality']

X_blanco = datos_vino_blanco.drop('quality', axis=1)
y_blanco = datos_vino_blanco['quality']

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train_tinto, X_test_tinto, y_train_tinto, y_test_tinto = train_test_split(X_tinto, y_tinto, test_size=0.2, random_state=42)
X_train_blanco, X_test_blanco, y_train_blanco, y_test_blanco = train_test_split(X_blanco, y_blanco, test_size=0.2, random_state=42)

# Normalizar los datos asegurándose de que solo las columnas numéricas sean normalizadas
scaler = StandardScaler()

X_train_tinto = scaler.fit_transform(X_train_tinto.select_dtypes(include=[np.number]))
X_test_tinto = scaler.transform(X_test_tinto.select_dtypes(include=[np.number]))
X_train_blanco = scaler.fit_transform(X_train_blanco.select_dtypes(include=[np.number]))
X_test_blanco = scaler.transform(X_test_blanco.select_dtypes(include=[np.number]))

# Entrenar y evaluar los modelos
models = {
    "LDA": LinearDiscriminantAnalysis(),
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "MLP": MLPClassifier(hidden_layer_sizes=(100,), max_iter=2000, random_state=42)  # Incrementar max_iter
}

results = {}

for name, model in models.items():
    model.fit(X_train_tinto, y_train_tinto)
    y_pred = model.predict(X_test_tinto)

    accuracy = accuracy_score(y_test_tinto, y_pred)
    cm = confusion_matrix(y_test_tinto, y_pred)
    report = classification_report(y_test_tinto, y_pred, zero_division=0)  # Ajustar zero_division

    results[name] = {
        "accuracy": accuracy,
        "confusion_matrix": cm,
        "classification_report": report
    }

# Convertir resultados a un DataFrame para facilitar la visualización
results_df = pd.DataFrame({
    'Model': results.keys(),
    'Accuracy': [results[model]['accuracy'] for model in results],
    'Confusion Matrix': [results[model]['confusion_matrix'] for model in results],
    'Classification Report': [results[model]['classification_report'] for model in results]
})

# Mostrar resultados
print(results_df[['Model', 'Accuracy']])
print("\nDetailed Classification Reports:\n")
for model in results:
    print(f"{model} Classification Report:\n", results[model]['classification_report'], "\n")

# Validación cruzada
# Combinar los datos de vino tinto y blanco
datos_vino_tinto['type'] = 'red'
datos_vino_blanco['type'] = 'white'
datos_vino = pd.concat([datos_vino_tinto, datos_vino_blanco], ignore_index=True)

# Separar características (X) y variable objetivo (y)
X = datos_vino.drop(columns=['quality', 'type'])
y = datos_vino['quality']

# Normalizar los datos asegurándose de que solo las columnas numéricas sean normalizadas
X_scaled = scaler.fit_transform(X.select_dtypes(include=[np.number]))

# Configurar la validación cruzada
kf = KFold(n_splits=5, shuffle=True, random_state=1)

# Evaluar cada modelo utilizando validación cruzada
cv_results = {}
for model_name, model in models.items():
    try:
        cv_scores = cross_val_score(model, X_scaled, y, cv=kf, scoring='accuracy')
        cv_results[model_name] = cv_scores
    except Exception as e:
        cv_results[model_name] = str(e)

# Mostrar resultados de validación cruzada
cv_results_df = pd.DataFrame(cv_results).T
cv_results_df.columns = [f'Fold {i+1}' for i in range(kf.get_n_splits())]
cv_results_df['Mean Accuracy'] = cv_results_df.mean(axis=1)
cv_results_df['Std Deviation'] = cv_results_df.std(axis=1)

# Mostrar resultados de validación cruzada
print(cv_results_df)

"""### Comparación de Resultados

Basándonos en las métricas proporcionadas:

**Precisión del Modelo**:
- LDA: 55.94%
- Regresión Logística: 57.50%
- Random Forest: 65.94%
- MLP: 61.56%

**Informes de Clasificación Detallados**:

**LDA**:
- Precisión: Varía de 0.00 a 0.64
- Recall: Varía de 0.00 a 0.74
- F1-score: Varía de 0.00 a 0.68
- Precisión Total: 55.94%

**Regresión Logística**:
- Precisión: Varía de 0.00 a 1.00
- Recall: Varía de 0.00 a 0.75
- F1-score: Varía de 0.00 a 0.69
- Precisión Total: 57.50%

**Random Forest**:
- Precisión: Varía de 0.00 a 0.71
- Recall: Varía de 0.00 a 0.74
- F1-score: Varía de 0.00 a 0.72
- Precisión Total: 65.94%

**MLP**:
- Precisión: Varía de 0.00 a 0.69
- Recall: Varía de 0.00 a 0.70
- F1-score: Varía de 0.00 a 0.70
- Precisión Total: 61.56%

**Resultados de Validación Cruzada**:

- **LDA**: Precisión Media: 53.82%, Desviación Estándar: 1.11%
- **Regresión Logística**: Precisión Media: 54.36%, Desviación Estándar: 0.85%
- **Random Forest**: Precisión Media: 68.18%, Desviación Estándar: 1.77%
- **MLP**: Precisión Media: 57.16%, Desviación Estándar: 0.55%

### Selección del Mejor Modelo

**Random Forest** se destaca no solo por tener la mayor precisión sino también por su robustez en términos de rendimiento en diferentes pliegues de validación cruzada.

**Random Forest** es el mejor modelo para este conjunto de datos debido a su alta precisión y buen rendimiento general.

### Análisis y Discusión de los Modelos

#### Random Forest

- **Ventajas**: Alta precisión, maneja bien las relaciones no lineales, robusto a los outliers.
- **Desventajas**: Mayor complejidad computacional en comparación con modelos lineales, interpretación menos intuitiva.

#### MLP

- **Ventajas**: Capaz de capturar relaciones complejas en los datos, consistencia en el rendimiento.
- **Desventajas**: Requiere ajuste fino de hiperparámetros, mayor tiempo de entrenamiento.

#### Regresión Logística y LDA

- **Ventajas**: Simplicidad, fácil interpretación.
- **Desventajas**: Menor precisión en comparación con Random Forest y MLP, asume relaciones lineales entre las características.

### Conclusión

Basándonos en la comparación de las métricas de rendimiento, la robustez y las ventajas/desventajas de cada modelo, **Random Forest** es la mejor elección para este problema de clasificación de la calidad del vino.

## 9. Presentación final y análisis de los resultados
"""

# Gráfico de precisión de los modelos
plt.figure(figsize=(10, 6))
sns.barplot(x=results_df['Model'], y=results_df['Accuracy'])
plt.title('Precisión de los Modelos')
plt.xlabel('Modelo')
plt.ylabel('Precisión')
plt.ylim(0, 1)
plt.show()

# Matrices de confusión
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
fig.suptitle('Matrices de Confusión de los Modelos')

for ax, (model, result) in zip(axes.flatten(), results.items()):
    sns.heatmap(result['confusion_matrix'], annot=True, fmt='d', cmap='Blues', ax=ax)
    ax.set_title(model)
    ax.set_xlabel('Predicho')
    ax.set_ylabel('Real')

plt.tight_layout()
plt.subplots_adjust(top=0.9)
plt.show()

# Resultados de validación cruzada
plt.figure(figsize=(10, 6))
cv_results_df['Mean Accuracy'].plot(kind='bar', yerr=cv_results_df['Std Deviation'], capsize=4)
plt.title('Precisión Media de Validación Cruzada con Desviación Estándar')
plt.xlabel('Modelo')
plt.ylabel('Precisión Media')
plt.ylim(0, 1)
plt.show()

"""### Resultados de la Precisión de los Modelos

A continuación se presentan los resultados de la precisión de los modelos:

- **LDA**: 55.94%
- **Regresión Logística**: 57.50%
- **Random Forest**: 65.94%
- **MLP**: 61.56%

### Informes de Clasificación Detallados

#### LDA
- Precisión: Varía de 0.00 a 0.64
- Recall: Varía de 0.00 a 0.74
- F1-score: Varía de 0.00 a 0.68
- Precisión Total: 55.94%

#### Regresión Logística
- Precisión: Varía de 0.00 a 1.00
- Recall: Varía de 0.00 a 0.75
- F1-score: Varía de 0.00 a 0.69
- Precisión Total: 57.50%

#### Random Forest
- Precisión: Varía de 0.00 a 0.71
- Recall: Varía de 0.00 a 0.74
- F1-score: Varía de 0.00 a 0.72
- Precisión Total: 65.94%

#### MLP
- Precisión: Varía de 0.00 a 0.69
- Recall: Varía de 0.00 a 0.70
- F1-score: Varía de 0.00 a 0.70
- Precisión Total: 61.56%

### Resultados de Validación Cruzada

- **LDA**: Precisión Media: 53.82%, Desviación Estándar: 1.11%
- **Regresión Logística**: Precisión Media: 54.36%, Desviación Estándar: 0.85%
- **Random Forest**: Precisión Media: 68.18%, Desviación Estándar: 1.77%
- **MLP**: Precisión Media: 57.16%, Desviación Estándar: 0.55%

### Gráficos de Resultados

#### Precisión de los Modelos
Este gráfico muestra la precisión de cada uno de los modelos entrenados:
- LDA
- Regresión Logística
- Random Forest
- MLP

#### Matrices de Confusión
Las matrices de confusión de los modelos entrenados se presentan a continuación. Estas matrices permiten visualizar el rendimiento de los modelos en términos de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.

#### Resultados de Validación Cruzada
Este gráfico muestra la precisión media obtenida mediante validación cruzada para cada modelo, junto con la desviación estándar.

### Análisis de Resultados

**Random Forest** se destaca no solo por tener la mayor precisión (65.94%) sino también por su robustez en términos de rendimiento en diferentes pliegues de validación cruzada (Precisión Media: 68.18%, Desviación Estándar: 1.77%). También muestra los valores más altos de precisión, recall y F1-score para la mayoría de las clases en comparación con otros modelos.

### Conclusión

Basándonos en la comparación de las métricas de rendimiento, la robustez y las ventajas/desventajas de cada modelo, **Random Forest** es la mejor elección para este problema de clasificación de la calidad del vino.

## 10. Discusión detallada del comportamiento de los modelos

### LDA (Linear Discriminant Analysis)

El modelo LDA obtuvo una precisión del 55.94%, que no es muy alta. Tuvo problemas principalmente con las clases menos representadas como las calificaciones 3, 4 y 8. Para las clases más frecuentes, como las calificaciones 5 y 6, LDA se desempeñó mejor, pero aún así, no fue suficiente.

Para mejorar LDA, podríamos crear nuevas características a partir de las ya existentes y probar diferentes enfoques de escalado y normalización. Aunque no tiene muchos hiperparámetros, ajustar los que tiene podría ayudar.

### Regresión Logística

La Regresión Logística alcanzó una precisión del 57.50%, un poco mejor que LDA. Al igual que LDA, este modelo tuvo un bajo rendimiento en las clases menos frecuentes. Por ejemplo, la clase 4 tuvo una precisión perfecta, pero un recall muy bajo, indicando que identificó muy pocas instancias de esta clase correctamente.

Podríamos mejorar la Regresión Logística aplicando técnicas de regularización como L1 o L2, y haciendo más ingeniería de características.

### Random Forest

Random Forest fue el modelo ganador con una precisión del 65.94%. Este modelo mostró un buen equilibrio entre precisión y recall para las clases más frecuentes (5, 6 y 7). Sin embargo, aún tuvo dificultades con las clases menos representadas.

Para mejorar Random Forest, podríamos aumentar el conjunto de datos con más muestras o aplicar técnicas de aumento de datos. Ajustar los hiperparámetros, como el número de árboles y la profundidad máxima, también podría aumentar la precisión. Además, podríamos combinar Random Forest con otros modelos para ver si obtenemos mejores resultados.

### MLP (Multi-Layer Perceptron)

El MLP alcanzó una precisión del 61.56%, mostrando un rendimiento sólido. Al igual que Random Forest, tuvo un buen desempeño en las clases frecuentes, pero luchó con las menos representadas. El MLP también mostró consistencia con una desviación estándar baja en la validación cruzada.

Para mejorar el MLP, podríamos ajustar su arquitectura probando diferentes configuraciones de capas y neuronas. Aplicar técnicas de regularización y dropout podría ayudar a evitar el sobreajuste. Además, experimentar con diferentes optimizadores y tasas de aprendizaje podría mejorar el rendimiento.

### Conclusión General

Aunque Random Forest es el modelo más robusto y preciso para este conjunto de datos, todos los modelos tienen margen de mejora, especialmente para las clases menos representadas. Algunas estrategias clave incluyen aumentar los datos, crear nuevas características y ajustar los hiperparámetros.

Cada modelo tiene sus propias ventajas y desventajas. La elección del modelo ideal puede depender de factores adicionales como el tiempo de entrenamiento, la interpretabilidad del modelo y los recursos computacionales disponibles.

En resumen, con estas mejoras podríamos lograr una clasificación más precisa y equilibrada de la calidad del vino.

## 11. Reflexión sobre lo aprendido

En primer lugar queremos expresar nuestro agradecimiento por las enseñanzas, apoyo, paciencia, y consejos durante el curso.

Algunos aspectos que nos gustaría destacar son los pequeños momentos en los cuales nos cuenta de sus perspectivas de la IA, uso, y comenta de casos reales y problematicas en la vida diaria, o en aplicaciones politicas, economicas, etc, esa vision es de gran valor. Debemos reconocer que la complejidad matemática subyacente en muchos de estos modelos ha representado un desafío en ocasiones, pero pues las grabaciones y la oportunidad de verlo virtual es una gran ayuda para repetir y si quiera balancear carga academica al no tener que asistir presencialmente. Ais mismo la implementacion a veces se torno un desafio, aunque, gracias a las herramientas y recursos disponibles en la actualidad, hemos podido sortear estos obstáculos con éxito. En retrospectiva fue un curso de mucho aprendizaje que y apasionante, nuevamente muchas gracias Profesor Alex.

Atentamente,

David Ricardo
Santiago Mesa
"""